{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import medleydb as mdb\n",
    "from medleydb import download\n",
    "import librosa\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hcqt_params():\n",
    "    bins_per_octave=120\n",
    "    n_octaves = 5\n",
    "    harmonics = [1, 2, 3, 4, 5, 6]\n",
    "    sr = 22050\n",
    "    fmin = 32.7\n",
    "    hop_length = 128\n",
    "    return bins_per_octave, n_octaves, harmonics, sr, fmin, hop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_hcqt(audio_fpath):\n",
    "    bins_per_octave, n_octaves, harmonics, sr, f_min, hop_length = get_hcqt_params()\n",
    "    y, fs = librosa.load(audio_fpath, sr=sr)\n",
    "\n",
    "    cqt_list = []\n",
    "    shapes = []\n",
    "    for h in harmonics:\n",
    "        cqt = librosa.cqt(\n",
    "            y, sr=fs, hop_length=hop_length, fmin=f_min*float(h),\n",
    "            n_bins=bins_per_octave*n_octaves,\n",
    "            bins_per_octave=bins_per_octave\n",
    "        )\n",
    "        cqt_list.append(cqt)\n",
    "        shapes.append(cqt.shape)\n",
    "    \n",
    "    shapes_equal = [s == shapes[0] for s in shapes]\n",
    "    if not all(shapes_equal):\n",
    "        min_time = np.min([s[1] for s in shapes])\n",
    "        new_cqt_list = []\n",
    "        for i, cqt in enumerate(cqt_list):\n",
    "            new_cqt_list.append(cqt[:, :min_time])\n",
    "            cqt_list.pop(i)\n",
    "        cqt_list = new_cqt_list\n",
    "\n",
    "    log_hcqt = 20.0*np.log10(np.abs(np.array(cqt_list)) + 0.0001)\n",
    "    log_hcqt = log_hcqt - np.min(log_hcqt)\n",
    "    log_hcqt = log_hcqt / np.max(log_hcqt)\n",
    "    return log_hcqt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_freq_grid():\n",
    "    bins_per_octave, n_octaves, harmonics, sr, f_min, hop_length = get_hcqt_params()\n",
    "    freq_grid = librosa.cqt_frequencies(\n",
    "        bins_per_octave*n_octaves, f_min, bins_per_octave=bins_per_octave\n",
    "    )\n",
    "    return freq_grid\n",
    "\n",
    "def get_time_grid(n_time_frames):\n",
    "    bins_per_octave, n_octaves, harmonics, sr, f_min, hop_length = get_hcqt_params()\n",
    "    time_grid = librosa.core.frames_to_time(\n",
    "        range(n_time_frames), sr=sr, hop_length=hop_length)\n",
    "    return time_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_to_bins(grid, start_bin_val, end_bin_val):\n",
    "    bin_centers = (grid[1:] + grid[:-1])/2.0\n",
    "    bins = np.concatenate([[start_bin_val], bin_centers, [end_bin_val]])\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_annotation_target(freq_grid, time_grid, annotation_times, annotation_freqs):\n",
    "\n",
    "    time_bins = grid_to_bins(time_grid, 0.0, time_grid[-1])\n",
    "    freq_bins = grid_to_bins(freq_grid, 0.0, freq_grid[-1])\n",
    "\n",
    "    annot_time_idx = np.digitize(annotation_times, time_bins) - 1\n",
    "    annot_freq_idx = np.digitize(annotation_freqs, freq_bins) - 1\n",
    "\n",
    "    annotation_target = np.zeros((len(freq_grid), len(time_grid)))\n",
    "    annotation_target[annot_freq_idx, annot_time_idx] = 1\n",
    "\n",
    "    return annotation_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_pitch_annotations(mtrack):\n",
    "    annot_times = []\n",
    "    annot_freqs = []\n",
    "    for stem in mtrack.stems.values():\n",
    "        data = stem.pitch_annotation\n",
    "        data2 = stem.pitch_estimate_pyin\n",
    "        if data is not None:\n",
    "            annot = data\n",
    "        elif data2 is not None:\n",
    "            annot = data2\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        annot = np.array(annot).T\n",
    "        annot_times.append(annot[0])\n",
    "        annot_freqs.append(annot[1])\n",
    "\n",
    "    annot_times = np.concatenate(annot_times)\n",
    "    annot_freqs = np.concatenate(annot_freqs)\n",
    "\n",
    "    return annot_times, annot_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_annot_target(annot_target, hcqt, annot_times, annot_freqs):\n",
    "    plt.figure(figsize=(15,30))\n",
    "    \n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.imshow(hcqt, origin='lower')\n",
    "    plt.axis('auto')\n",
    "    plt.axis('tight')\n",
    "    \n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.imshow(annot_target, origin='lower')\n",
    "    plt.axis('auto')\n",
    "    plt.axis('tight')\n",
    "\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(annot_times, annot_freqs, ',')\n",
    "    plt.axis('tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_input_output_pairs(mtrack):\n",
    "    hcqt = compute_hcqt(mtrack.mix_path)\n",
    "\n",
    "    freq_grid = get_freq_grid()\n",
    "    time_grid = get_time_grid(len(hcqt[0][0]))\n",
    "\n",
    "    annot_times, annot_freqs = get_all_pitch_annotations(mtrack)\n",
    "\n",
    "    annot_target = create_annotation_target(\n",
    "        freq_grid, time_grid, annot_times, annot_freqs\n",
    "    )\n",
    "    plot_annot_target(annot_target, hcqt[0], annot_times, annot_freqs)\n",
    "    return hcqt, annot_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_input_output_pairs_solo_pitch(audio_path, annot_times, annot_freqs, plot=False):\n",
    "    hcqt = compute_hcqt(audio_path)\n",
    "\n",
    "    freq_grid = get_freq_grid()\n",
    "    time_grid = get_time_grid(len(hcqt[0][0]))\n",
    "    annot_target = create_annotation_target(\n",
    "        freq_grid, time_grid, annot_times, annot_freqs\n",
    "    )\n",
    "    if plot:\n",
    "        plot_annot_target(annot_target, hcqt[0], annot_times, annot_freqs)\n",
    "\n",
    "    return hcqt, annot_target, freq_grid, time_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AClassicEducation_NightOwl\n",
      "    > Stem 8 ['male singer']\n",
      "AimeeNorwich_Child\n",
      "    > Stem 4 ['female singer']\n",
      "AimeeNorwich_Flying\n",
      "    > Stem 4 ['clean electric guitar']\n",
      "AlexanderRoss_GoodbyeBolero\n",
      "    > Stem 6 ['male singer']\n",
      "AlexanderRoss_VelvetCurtain\n",
      "    > Stem 6 ['male singer']\n",
      "AmarLal_Rest\n",
      "    > Stem 1 ['clean electric guitar']\n",
      "AmarLal_SpringDay1\n",
      "    > Stem 1 ['acoustic guitar']\n",
      "Auctioneer_OurFutureFaces\n",
      "    > Stem 8 ['male singer']\n",
      "AvaLuna_Waterduct\n",
      "    > Stem 8 ['male singer']\n",
      "BigTroubles_Phantom\n",
      "    > Stem 4 ['male singer']\n",
      "BrandonWebster_DontHearAThing\n",
      "    > Stem 2 ['female singer']\n",
      "BrandonWebster_YesSirICanFly\n",
      "    > Stem 2 ['male singer']\n",
      "CelestialShore_DieForUs\n",
      "    > Stem 1 ['male singer']\n",
      "ChrisJacoby_BoothShotLincoln\n",
      "ChrisJacoby_PigsFoot\n",
      "    > Stem 2 ['mandolin']\n",
      "ClaraBerryAndWooldog_AirTraffic\n",
      "    > Stem 8 ['female singer']\n",
      "ClaraBerryAndWooldog_Boys\n",
      "    > Stem 6 ['female singer']\n",
      "ClaraBerryAndWooldog_Stella\n",
      "    > Stem 7 ['female singer']\n",
      "ClaraBerryAndWooldog_TheBadGuys\n",
      "    > Stem 2 ['female singer']\n",
      "ClaraBerryAndWooldog_WaltzForMyVictims\n",
      "    > Stem 5 ['female singer']\n",
      "Creepoid_OldTree\n",
      "    > Stem 8 ['male singer']\n",
      "CroqueMadame_Oil\n",
      "    > Stem 2 ['clean electric guitar']\n",
      "CroqueMadame_Pilot\n",
      "    > Stem 2 ['clean electric guitar']\n",
      "Debussy_LenfantProdigue\n",
      "    > Stem 1 ['male singer']\n",
      "DreamersOfTheGhetto_HeavyLove\n",
      "    > Stem 6 ['male singer']\n",
      "EthanHein_1930sSynthAndUprightBass\n",
      "    > Stem 4 ['double bass']\n",
      "EthanHein_BluesForNofi\n",
      "EthanHein_GirlOnABridge\n",
      "    > Stem 5 ['distorted electric guitar']\n",
      "EthanHein_HarmonicaFigure\n",
      "FacesOnFilm_WaitingForGa\n",
      "    > Stem 3 ['male singer']\n",
      "FamilyBand_Again\n",
      "    > Stem 9 ['female singer']\n",
      "Grants_PunchDrunk\n",
      "Handel_TornamiAVagheggiar\n",
      "    > Stem 1 ['female singer']\n",
      "    > Something failed :(\n",
      "HeladoNegro_MitadDelMundo\n",
      "    > Stem 8 ['male singer']\n",
      "HezekiahJones_BorrowedHeart\n",
      "    > Stem 10 ['male singer']\n",
      "    > Something failed :(\n",
      "HopAlong_SisterCities\n",
      "    > Stem 7 ['female singer']\n",
      "InvisibleFamiliars_DisturbingWildlife\n",
      "    > Stem 9 ['male singer']\n",
      "JoelHelander_Definition\n",
      "    > Stem 2 ['violin']\n",
      "    > Something failed :(\n",
      "JoelHelander_ExcessiveResistancetoChange\n",
      "    > Stem 1 ['tack piano']\n",
      "    > Something failed :(\n",
      "JoelHelander_IntheAtticBedroom\n",
      "    > Stem 1 ['violin']\n",
      "    > Something failed :(\n",
      "KarimDouaidy_Hopscotch\n",
      "    > Stem 7 ['oud']\n",
      "KarimDouaidy_Yatora\n",
      "    > Stem 3 ['oud']\n",
      "    > Something failed :(\n",
      "LizNelson_Coldwar\n",
      "    > Stem 2 ['female singer']\n",
      "    > Something failed :(\n",
      "LizNelson_ImComingHome\n",
      "    > Stem 4 ['female singer']\n",
      "    > Something failed :(\n",
      "LizNelson_Rainfall\n",
      "    > Stem 1 ['female singer']\n",
      "    > Something failed :(\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"../output/training_data/\"\n",
    "\n",
    "failed_tracks = [\n",
    "    'ChrisJacoby_BoothShotLincoln',\n",
    "    'HezekiahJones_BorrowedHeart',\n",
    "    'Handel_TornamiAVagheggiar',\n",
    "    'JoelHelander_Definition',\n",
    "    'JoelHelander_ExcessiveResistancetoChange',\n",
    "    'JoelHelander_IntheAtticBedroom'\n",
    "]\n",
    "\n",
    "mtracks = mdb.load_all_multitracks(dataset_version=['V1'])\n",
    "for mtrack in mtracks:\n",
    "    print(mtrack.track_id)\n",
    "    \n",
    "    if mtrack.track_id in failed_tracks:\n",
    "        continue\n",
    "    \n",
    "    stem = mtrack.predominant_stem\n",
    "    if stem is None:\n",
    "        continue\n",
    "\n",
    "    data = stem.pitch_annotation\n",
    "    save_path = os.path.join(\n",
    "        save_dir,\n",
    "        \"{}_STEM_{}.npz\".format(mtrack.track_id, stem.stem_idx)\n",
    "    )\n",
    "\n",
    "    if data is not None:\n",
    "        print(\"    > Stem {} {}\".format(stem.stem_idx, stem.instrument))\n",
    "        annot = np.array(data).T\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    if os.path.exists(save_path):\n",
    "        one_stem_done = True\n",
    "        continue\n",
    "\n",
    "    if not os.path.exists(stem.audio_path):\n",
    "        print(\"        >downloading stem...\")\n",
    "        download.download_stem(mtrack, stem.stem_idx)\n",
    "        print(\"         done!\")\n",
    "\n",
    "    try:\n",
    "        data_in, data_out, freq, time = get_input_output_pairs_solo_pitch(\n",
    "            stem.audio_path, annot[0], annot[1]\n",
    "        )\n",
    "\n",
    "        np.savez(save_path, data_in=data_in, data_out=data_out, freq=freq, time=time)\n",
    "    except:\n",
    "        print(\"    > Something failed :(\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mtrack = mdb.MultiTrack(\"MusicDelta_Beatles\")\n",
    "data_input, data_target = get_input_output_pairs(mtrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
