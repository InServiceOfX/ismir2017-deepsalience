{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Reshape\n",
    "from keras.layers import Convolution2D, Convolution3D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import pescador\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_to_prob(sum_array):\n",
    "    sum_shift = sum_array + 1.0\n",
    "    total = np.sum(sum_shift)\n",
    "    return sum_shift/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_data(input_cqt):\n",
    "    norm_data = input_cqt - np.min(input_cqt)\n",
    "    norm_data = norm_data / np.max(norm_data)\n",
    "    return norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def __grab_patch_input(f, t, n_f, n_t, n_harms, x_data):\n",
    "    return np.transpose(\n",
    "        x_data[:, f: f + n_f, t: t + n_t], (1, 2, 0)).reshape(1, n_f, n_t, n_harms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __grab_patch_output(f, t, n_f, n_t, y_data):\n",
    "    return y_data[f: f + n_f, t: t + n_t].reshape(1, n_f, n_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def patch_generator(input_cqt, pitch_activation_map, patch_size=(20, 20)):\n",
    "    norm_data = normalize_data(input_cqt)\n",
    "\n",
    "    n_harms, n_freqs, n_times = norm_data.shape\n",
    "    n_f, n_t = patch_size\n",
    "\n",
    "    f_indices = np.arange(0, n_freqs - n_f)\n",
    "    t_indices = np.arange(0, n_times - n_t)\n",
    "    f_dist = sum_to_prob(pitch_activation_map[:-n_f, :].sum(axis=1))\n",
    "    t_dist = sum_to_prob(pitch_activation_map[:, :-n_t].sum(axis=0))\n",
    "\n",
    "    while True:\n",
    "        f = np.random.choice(f_indices, p=f_dist)\n",
    "        t = np.random.choice(t_indices, p=t_dist)\n",
    "        x = __grab_patch_input(f, t, n_f, n_t, n_harms, norm_data)\n",
    "        y = __grab_patch_output(f, t, n_f, n_t, pitch_activation_map)\n",
    "        yield dict(X=x, Y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stride_cqt(input_cqt, patch_size=(20, 20)):\n",
    "    norm_data = normalize_data(input_cqt)\n",
    "\n",
    "    n_harms, n_freqs, n_times = norm_data.shape\n",
    "    n_f, n_t = patch_size\n",
    "\n",
    "    f_indices = np.arange(0, n_freqs - n_f, n_f/2)\n",
    "    t_indices = np.arange(0, n_times - n_t, n_t/2)\n",
    "    for f in f_indices:\n",
    "        for t in t_indices:\n",
    "            x = __grab_patch_input(f, t, n_f, n_t, n_harms, norm_data)\n",
    "            yield(dict(X=x, t=t, f=f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def keras_generator(data_list, patch_size=(20, 20), n_samples=10000,\n",
    "                    n_active=1000, with_replacement=False, batch_size=1024):\n",
    "    streams = []\n",
    "    for data_in, data_out in data_list:\n",
    "        streams.append(\n",
    "            pescador.Streamer(\n",
    "                patch_generator, data_in, data_out, patch_size=patch_size\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    stream_mux = pescador.Mux(streams, 2,\n",
    "        with_replacement=True, lam=None\n",
    "    )\n",
    "\n",
    "    batch_generator = pescador.buffer_batch(stream_mux.generate(), batch_size)\n",
    "\n",
    "    for batch in batch_generator:\n",
    "        yield (batch['X'], batch['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_files = glob.glob(os.path.join(\"../output/training_data/*.npz\"))\n",
    "\n",
    "data = [np.load(fpath, mmap_mode='r') for fpath in data_files][:16]\n",
    "data_list = [\n",
    "    [d['data_in'], d['data_out']] for d in data\n",
    "]\n",
    "\n",
    "train_samples = int(np.round(len(data_files) * 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_generator = keras_generator(data_list[:train_samples])\n",
    "validation_generator = keras_generator(data_list[train_samples:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of convolutional filters to use\n",
    "nb_filters = 100\n",
    "# size of pooling area for max pooling\n",
    "pool_size = (2, 2)\n",
    "# convolution kernel size\n",
    "kernel_size = (3, 3)\n",
    "\n",
    "kernel_dim1 = 3\n",
    "kernel_dim2 = 3\n",
    "kernel_dim3 = 1\n",
    "\n",
    "input_shape = (20, 20, 6)\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "y1 = Convolution2D(\n",
    "    64, 10, 10, border_mode='same', activation='tanh', name='bendy'\n",
    ")(inputs)\n",
    "y2 = Convolution2D(\n",
    "    32, 5, 5, border_mode='same', activation='tanh', name='smoothy'\n",
    ")(y1)\n",
    "y3 = Convolution2D(\n",
    "    1, 1, 1, border_mode='valid', activation='sigmoid', name='squishy'\n",
    ")(y2)\n",
    "predictions = Reshape((20, 20), name='reshapeeee')(y3)\n",
    "\n",
    "model = Model(input=inputs, output=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loss binary cross entropy\n",
    "model.compile(loss='kld',\n",
    "              optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary(line_length=103)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_per_epoch = 1024 * 100\n",
    "nb_epochs = 10\n",
    "nb_val_samples = 1024\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator, samples_per_epoch, nb_epochs, verbose=1,\n",
    "    validation_data=validation_generator, nb_val_samples=nb_val_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot filters\n",
    "conv_layer = model.get_layer(name='bendy')\n",
    "weights = conv_layer.get_weights()\n",
    "weight_array = weights[0]\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(64):\n",
    "    plt.subplot(8, 8, i+1)\n",
    "    plt.imshow(weight_array[:, :, 0, i], origin='lower')\n",
    "    plt.axis('square')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot filters\n",
    "conv_layer = model.get_layer(name='smoothy')\n",
    "weights = conv_layer.get_weights()\n",
    "weight_array = weights[0]\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(32):\n",
    "    plt.subplot(8, 4, i+1)\n",
    "    plt.imshow(weight_array[:, :, 0, i], origin='lower')\n",
    "    plt.axis('square')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_stuff(X, Y, Y_pred):\n",
    "    sns.set_style('white')\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.title(\"prediction\")\n",
    "    plt.imshow(Y_pred[0], origin='lower', cmap='hot', vmin=0, vmax=1)\n",
    "    plt.axis('auto')\n",
    "#     plt.xlim(a, b)\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.title('target')\n",
    "    plt.imshow(Y[0], origin='lower', cmap='hot', vmin=0, vmax=1)\n",
    "    plt.axis('auto')\n",
    "#     plt.xlim(a, b)\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.title('input')\n",
    "    plt.imshow(X[0, :, :, 0], origin='lower', cmap='hot', vmin=0, vmax=1)\n",
    "    plt.axis('auto')\n",
    "#     plt.xlim(a, b)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for X, Y in validation_generator:\n",
    "    Y_pred = model.predict(X)\n",
    "    plot_stuff(X, Y, Y_pred)\n",
    "    break\n",
    "    if np.sum(Y[0].flatten()) > 0:\n",
    "        plot_stuff(X, Y, Y_pred)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for X, Y in train_generator:\n",
    "    for x, y in zip(X, Y):\n",
    "        if np.sum(y.flatten()) > 0:\n",
    "            plt.figure(figsize=(15, 15))\n",
    "            plt.subplot(2, 1, 1)\n",
    "            plt.imshow(x[:, :, 0], origin='lower', cmap='hot')\n",
    "            plt.axis('square')\n",
    "\n",
    "            plt.subplot(2, 1, 2)\n",
    "            plt.imshow(y, origin='lower', cmap='hot')\n",
    "            plt.axis('square')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OLAP_KERNEL = np.zeros((20, 20))\n",
    "for i in range(11):\n",
    "    for j in range(11):\n",
    "        val = 0.1*float(i)*0.1*float(j)\n",
    "        OLAP_KERNEL[i, j] = val\n",
    "        OLAP_KERNEL[-i, j] = val\n",
    "        OLAP_KERNEL[i, -j] = val\n",
    "        OLAP_KERNEL[-i, -j] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_full_track_prediction(data_in, model):\n",
    "\n",
    "    n_harms, n_freqs, n_times = data_in.shape\n",
    "    n_f, n_t = (20, 20)\n",
    "\n",
    "    prediction = np.zeros((n_freqs, n_times))\n",
    "\n",
    "    cqt_patch_generator = stride_cqt(data_in)\n",
    "\n",
    "    for d in cqt_patch_generator:\n",
    "        f = d['f']\n",
    "        t = d['t']\n",
    "        y_pred = model.predict(d['X'].reshape(1, n_f, n_t, n_harms)).reshape(n_f, n_t)\n",
    "#         prediction[f: f + n_f, t: t + n_t] += y_pred * OLAP_KERNEL\n",
    "        prediction[f: f + n_f, t: t + n_t] = y_pred\n",
    "\n",
    "    return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_prediction = get_full_track_prediction(dat3['data_in'], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a, b = (10000, 20000)\n",
    "\n",
    "sns.set_style('white')\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(test_prediction**10, origin='lower', cmap='hot')\n",
    "# plt.imshow((1.0 - test_prediction)**1000, origin='lower', cmap='hot')\n",
    "plt.axis('auto')\n",
    "plt.xlim(a, b)\n",
    "# plt.colorbar()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(dat3['data_out'], origin='lower', cmap='hot')\n",
    "plt.axis('auto')\n",
    "plt.xlim(a, b)\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(dat3['data_in'][0, :, :], origin='lower', cmap='hot')\n",
    "plt.axis('auto')\n",
    "plt.xlim(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(dat3['data_in'][0], origin='lower', cmap='hot')\n",
    "plt.axis('auto')\n",
    "plt.xlim(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(dat3['data_out'], origin='lower', cmap='hot')\n",
    "plt.axis('auto')\n",
    "plt.xlim(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
